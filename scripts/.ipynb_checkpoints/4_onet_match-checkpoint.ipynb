{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa1eec4b-2e53-4893-beed-a3e5dd4f1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "###script to match onet skills\n",
    "##create an embedding space of O*NET skills and then of abstracts based on similarity of skills\n",
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import textwrap\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import torch\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c5e3c32-f64c-4f43-9d17-2cf95c82ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##grant data\n",
    "nsf_df = pd.read_csv('../output/grants.csv')\n",
    "\n",
    "##O*NET skills database (from https://www.onetcenter.org/database.html#all-files)\n",
    "onet_df = pd.read_excel('../input/Content Model Reference.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4930baa-d8c2-4f09-aae1-ee295bc03e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create broad category labels for plotting\n",
    "##broadest label\n",
    "onet_df['Category'] = onet_df['Element ID'].astype(str).str[0]\n",
    "##second broadest label\n",
    "onet_df['Category2'] = onet_df['Element ID'].astype(str).str[:3]\n",
    "\n",
    "#limit skills to categories 1a 4a (following Sabet et al) \n",
    "# and 2 (\"skills knowledge education\")\n",
    "# and tasks, technology skills\n",
    "onet_df = onet_df[onet_df[\"Category2\"].isin(['1.A', '4.A', '2.A', '2.B', '2.C', '2.D'])]\n",
    "#remove header rows- rows where 'Element ID' has fewer than 4 characters\n",
    "onet_df = onet_df[onet_df['Element ID'].str.len()>3]\n",
    "\n",
    "#reset index\n",
    "onet_df = onet_df.reset_index(drop=True)\n",
    "\n",
    "#drop repeated 'Engineering and Technology'\n",
    "onet_df = onet_df.drop(125)\n",
    "\n",
    "#reset index\n",
    "onet_df = onet_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7dfef355-8041-4411-a628-433b29d45bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create embedding from O*NET description\n",
    "#using pretrained sentence-transformers model\n",
    "sentences = onet_df['Description']\n",
    "embedding = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0038a56-8cfc-4eec-8885-5325b683d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create dataframe of sentences and embeddings\n",
    "\n",
    "d = {'element':onet_df['Element Name'], 'sent': sentences, \n",
    "     'embed': embedding.tolist(), 'label1':onet_df['Category'],\n",
    "    'label2':onet_df['Category2']}\n",
    "embeddings_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cca764a-8863-4d31-a035-a920943e0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a new column in the dataframe and add all skills for which \n",
    "##cosine similarity to a sentence in that abstract is above a certain value\n",
    "\n",
    "#set the embedding list as the O*Net skills embeddings\n",
    "emb2_list = embedding\n",
    "\n",
    "#set lists to fill for validation df\n",
    "awards_list = []\n",
    "match_sent = []\n",
    "match_skill = []\n",
    "cos_sim_values = []\n",
    "\n",
    "#set list to fill for grants df column\n",
    "onet_column = []\n",
    "\n",
    "#loop through the abstracts\n",
    "for j in range(len(nsf_df)):\n",
    "    #tokenize the sentences in the abstract\n",
    "    abstract = nsf_df['Abstract'][j]\n",
    "    if not pd.isna(abstract):\n",
    "        phrases = sent_tokenize(abstract)\n",
    "        #set the award number to record in validation df\n",
    "        award = nsf_df['AwardNumber'][j]\n",
    "        #create empty list for skills\n",
    "        skill_list = []\n",
    "        #for each sentence\n",
    "        for phrase in phrases:\n",
    "            #encode that sentence in the pretrained model\n",
    "            emb1 = model.encode(phrase)\n",
    "        \n",
    "            #create empty matrix for cosine measures\n",
    "            cos_sim = []\n",
    "    \n",
    "            #calculate all the cosine simliarites\n",
    "            for emb2 in emb2_list:\n",
    "                sim_measure = util.pytorch_cos_sim(emb1, emb2)[0][0].item()\n",
    "                cos_sim.append(sim_measure)\n",
    "                if sim_measure >.5:\n",
    "                    row = np.where(emb2_list == emb2)[0][0]\n",
    "                    #record the award for validation df\n",
    "                    awards_list.append(award)\n",
    "                    #record the sentence for validation df\n",
    "                    match_sent.append(phrase)\n",
    "                    # record the matched skill for validation df\n",
    "                    match_skill.append(embeddings_df['element'][row])\n",
    "                    # record the value for validation df\n",
    "                    cos_sim_values.append(sim_measure)\n",
    "                    #add matched skill to list for grants df\n",
    "                    skill_list.append(str(embeddings_df['element'][row]))\n",
    "    \n",
    "        #remove repeats\n",
    "        skill_list=list(set(skill_list))\n",
    "        #remove punctuation\n",
    "        skill_list = str(skill_list)\n",
    "        skill_list = re.sub('\\[','',skill_list)\n",
    "        skill_list = re.sub('\\]','',skill_list)\n",
    "        skill_list = re.sub('\\'','',skill_list)\n",
    "    #if abstract blank\n",
    "    else:\n",
    "        skill_list = \"\"\n",
    "    onet_column.append(skill_list)\n",
    "\n",
    "nsf_df ['O*Net Skills']= onet_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "957893b4-a0d4-438f-bde2-21db5b4c4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make validation dataframe\n",
    "d = {'Award':awards_list, 'Sentence': match_sent, \n",
    "     'Skill': match_skill, 'Similarity Value':cos_sim_values}\n",
    "validation_df = pd.DataFrame(data=d)\n",
    "validation_df.to_csv('../output/onet_matching.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a77fcce8-409c-43ee-a504-f5867dbe5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeat extraction for Outcome Reports\n",
    "#set the embedding list as the O*Net skills embeddings\n",
    "emb2_list = embedding\n",
    "\n",
    "#set lists to fill for validation df\n",
    "awards_list = []\n",
    "match_sent = []\n",
    "match_skill = []\n",
    "cos_sim_values = []\n",
    "\n",
    "#set list to fill for grants df column\n",
    "onet_column = []\n",
    "\n",
    "#loop through the abstracts\n",
    "for j in range(len(nsf_df)):\n",
    "    #tokenize the sentences in the abstract\n",
    "    abstract = nsf_df['Outcome Report'][j]\n",
    "    if not pd.isna(abstract):\n",
    "        phrases = sent_tokenize(abstract)\n",
    "        #set the award number to record in validation df\n",
    "        award = nsf_df['AwardNumber'][j]\n",
    "        #create empty list for skills\n",
    "        skill_list = []\n",
    "        #for each sentence\n",
    "        for phrase in phrases:\n",
    "            #encode that sentence in the pretrained model\n",
    "            emb1 = model.encode(phrase)\n",
    "        \n",
    "            #create empty matrix for cosine measures\n",
    "            cos_sim = []\n",
    "    \n",
    "            #calculate all the cosine simliarites\n",
    "            for emb2 in emb2_list:\n",
    "                sim_measure = util.pytorch_cos_sim(emb1, emb2)[0][0].item()\n",
    "                cos_sim.append(sim_measure)\n",
    "                if sim_measure >.5:\n",
    "                    row = np.where(emb2_list == emb2)[0][0]\n",
    "                    #record the award for validation df\n",
    "                    awards_list.append(award)\n",
    "                    #record the sentence for validation df\n",
    "                    match_sent.append(phrase)\n",
    "                    # record the matched skill for validation df\n",
    "                    match_skill.append(embeddings_df['element'][row])\n",
    "                    # record the value for validation df\n",
    "                    cos_sim_values.append(sim_measure)\n",
    "                    #add matched skill to list for grants df\n",
    "                    skill_list.append(str(embeddings_df['element'][row]))\n",
    "    \n",
    "        #remove repeats\n",
    "        skill_list=list(set(skill_list))\n",
    "        #remove punctuation\n",
    "        skill_list = str(skill_list)\n",
    "        skill_list = re.sub('\\[','',skill_list)\n",
    "        skill_list = re.sub('\\]','',skill_list)\n",
    "        skill_list = re.sub('\\'','',skill_list)\n",
    "    #if abstract blank\n",
    "    else:\n",
    "        skill_list = \"\"\n",
    "    onet_column.append(skill_list)\n",
    "\n",
    "nsf_df ['O*Net Skills Outcome Reports']= onet_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5a396ef-7863-4d1f-8902-ac1628699b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save grants csv\n",
    "nsf_df.to_csv('../output/grants.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fbb0e-3b85-4287-97b9-e88fa92935f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
